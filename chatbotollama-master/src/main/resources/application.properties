model.tokenizer=gpt-3
langchain4j.open-ai.chat-model.temperature=0.0
langchain4j.open-ai.chat-model.timeout=PT60S
langchain4j.open-ai.chat-model.max-retries=1
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true
logging.level.dev.langchain4j=info
logging.level.dev.ai4j.openai4j=debug
logging.level.dev.langchain4j.agent=info
bc.filepath=C:\\Users\\AmineLimem\\Desktop\\amineai
embedding.tokensplit=1000
embedding.tokenseacrhscore=0.6
embedding.maxSearchResults=1
chat.history.size=5
ollama.model=openchat
ollama.baseuri=http://localhost:11434
ollama.model.temperature=0.0

